{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from stheno import GP, EQ\n",
    "x = np.linspace(0, 2, 10)           # Some points to predict at\n",
    "y = x ** 2                          # Some observations\n",
    "f = GP(EQ())                        # Construct Gaussian process.\n",
    "f_post = f | (f(x), y)              # Compute the posterior.\n",
    "pred = f_post(np.array([1, 2, 3]))  # Predict!\n",
    "print(f\"{pred.mean=}\")\n",
    "print(f\"{pred.var=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from wbml.plot import tweak\n",
    "\n",
    "from stheno import B, GP, EQ\n",
    "\n",
    "# Define points to predict at.\n",
    "x = B.linspace(0, 10, 100)\n",
    "x_obs = B.linspace(0, 7, 20)\n",
    "\n",
    "# Construct a prior.\n",
    "f = GP(EQ().periodic(5.0))\n",
    "\n",
    "# Sample a true, underlying function and noisy observations.\n",
    "f_true, y_obs = f.measure.sample(f(x), f(x_obs, 0.5))\n",
    "\n",
    "# Now condition on the observations to make predictions.\n",
    "f_post = f | (f(x_obs, 0.5), y_obs)\n",
    "mean, lower, upper = f_post(x).marginal_credible_bounds()\n",
    "\n",
    "# Plot result.\n",
    "plt.plot(x, f_true, label=\"True\", style=\"test\")\n",
    "plt.scatter(x_obs, y_obs, label=\"Observations\", style=\"train\", s=20)\n",
    "plt.plot(x, mean, label=\"Prediction\", style=\"pred\")\n",
    "plt.fill_between(x, lower, upper, style=\"pred\")\n",
    "tweak()\n",
    "plt.savefig(\"readme_example1_simple_regression.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from wbml.plot import tweak\n",
    "\n",
    "from stheno import B, GP, EQ\n",
    "\n",
    "# Define points to predict at.\n",
    "x = B.linspace(0, 10, 100)\n",
    "x_obs = B.linspace(0, 7, 20)\n",
    "\n",
    "# Construct a prior.\n",
    "f = GP(EQ().periodic(5.0))\n",
    "\n",
    "# Sample a true, underlying function and noisy observations.\n",
    "f_true, y_obs = f.measure.sample(f(x), f(x_obs, 0.5))\n",
    "\n",
    "# Now condition on the observations to make predictions.\n",
    "f_post = f | (f(x_obs, 0.5), y_obs)\n",
    "mean, lower, upper = f_post(x).marginal_credible_bounds()\n",
    "\n",
    "# Plot result.\n",
    "plt.plot(x, f_true, label=\"True\", style=\"test\")\n",
    "plt.scatter(x_obs, y_obs, label=\"Observations\", style=\"train\", s=20)\n",
    "plt.plot(x, mean, label=\"Prediction\", style=\"pred\")\n",
    "plt.fill_between(x, lower, upper, style=\"pred\")\n",
    "tweak()\n",
    "plt.savefig(\"readme_example1_simple_regression.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimisation with Varz\n",
    "- Parameterized\n",
    "    - Unbounded\n",
    "    - Positive \n",
    "        - 正の値に制限\n",
    "    - Bounded\n",
    "        - args : (lower, upper)\n",
    "    - LowerTriangular\n",
    "        - args : (shape)\n",
    "    - PositiveDefinite\n",
    "        - args : (shape)\n",
    "    - Orthogonal\n",
    "        - args : (shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lab as B\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from varz import Vars, minimise_l_bfgs_b, parametrised, Positive\n",
    "from wbml.plot import tweak\n",
    "\n",
    "from stheno.torch import EQ, GP\n",
    "\n",
    "# Increase regularisation because PyTorch defaults to 32-bit floats.\n",
    "B.epsilon = 1e-6\n",
    "\n",
    "# Define points to predict at.\n",
    "x = torch.linspace(0, 2, 100)\n",
    "x_obs = torch.linspace(0, 2, 50)\n",
    "\n",
    "# Sample a true, underlying function and observations with observation noise `0.05`.\n",
    "f_true = torch.sin(5 * x)\n",
    "y_obs = torch.sin(5 * x_obs) + 0.05**0.5 * torch.randn(50)\n",
    "\n",
    "\n",
    "def model(vs):\n",
    "    \"\"\"Construct a model with learnable parameters.\"\"\"\n",
    "    p = vs.struct  # Varz handles positivity (and other) constraints.\n",
    "    kernel = p.variance.positive() * EQ().stretch(p.scale.positive())\n",
    "    return GP(kernel), p.noise.positive()\n",
    "\n",
    "\n",
    "@parametrised   #  To indicate that an argument of the function is a variableえ\n",
    "def model_alternative(vs, scale: Positive, variance: Positive, noise: Positive):\n",
    "    \"\"\"Equivalent to :func:`model`, but with `@parametrised`.\"\"\"\n",
    "    kernel = variance * EQ().stretch(scale)\n",
    "    return GP(kernel), noise\n",
    "\n",
    "\n",
    "vs = Vars(torch.float32)\n",
    "f, noise = model(vs)\n",
    "\n",
    "# Condition on observations and make predictions before optimisation.\n",
    "f_post = f | (f(x_obs, noise), y_obs)\n",
    "prior_before = f, noise\n",
    "pred_before = f_post(x, noise).marginal_credible_bounds()\n",
    "\n",
    "\n",
    "def objective(vs):\n",
    "    f, noise = model(vs)\n",
    "    evidence = f(x_obs, noise).logpdf(y_obs)\n",
    "    return -evidence\n",
    "\n",
    "\n",
    "# Learn hyperparameters.\n",
    "minimise_l_bfgs_b(objective, vs)\n",
    "\n",
    "f, noise = model(vs)\n",
    "\n",
    "# Condition on observations and make predictions after optimisation.\n",
    "f_post = f | (f(x_obs, noise), y_obs)\n",
    "prior_after = f, noise\n",
    "pred_after = f_post(x, noise).marginal_credible_bounds()\n",
    "\n",
    "\n",
    "def plot_prediction(prior, pred):\n",
    "    f, noise = prior\n",
    "    mean, lower, upper = pred\n",
    "    plt.scatter(x_obs, y_obs, label=\"Observations\", style=\"train\", s=20)\n",
    "    plt.plot(x, f_true, label=\"True\", style=\"test\")\n",
    "    plt.plot(x, mean, label=\"Prediction\", style=\"pred\")\n",
    "    plt.fill_between(x, lower, upper, style=\"pred\")\n",
    "    plt.ylim(-2, 2)\n",
    "    plt.text(\n",
    "        0.02,\n",
    "        0.02,\n",
    "        f\"var = {f.kernel.factor(0):.2f}, \"\n",
    "        f\"scale = {f.kernel.factor(1).stretches[0]:.2f}, \"\n",
    "        f\"noise = {noise:.2f}\",\n",
    "        transform=plt.gca().transAxes,\n",
    "    )\n",
    "    tweak()\n",
    "\n",
    "\n",
    "# Plot result.\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Before optimisation\")\n",
    "plot_prediction(prior_before, pred_before)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"After optimisation\")\n",
    "plot_prediction(prior_after, pred_after)\n",
    "plt.savefig(\"readme_example12_optimisation_varz.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimisation with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lab as B\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from wbml.plot import tweak\n",
    "\n",
    "from stheno.torch import EQ, GP\n",
    "\n",
    "# Increase regularisation because PyTorch defaults to 32-bit floats.\n",
    "B.epsilon = 1e-6\n",
    "\n",
    "# Define points to predict at.\n",
    "x = torch.linspace(0, 2, 100)\n",
    "x_obs = torch.linspace(0, 2, 50)\n",
    "\n",
    "# Sample a true, underlying function and observations with observation noise `0.05`.\n",
    "f_true = torch.sin(5 * x)\n",
    "y_obs = torch.sin(5 * x_obs) + 0.05**0.5 * torch.randn(50)\n",
    "\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    \"\"\"A GP model with learnable parameters.\"\"\"\n",
    "\n",
    "    def __init__(self, init_var=0.3, init_scale=1, init_noise=0.2):\n",
    "        super().__init__()\n",
    "        # Ensure that the parameters are positive and make them learnable.\n",
    "        self.log_var = torch.nn.Parameter(torch.log(torch.tensor(init_var)))\n",
    "        self.log_scale = torch.nn.Parameter(torch.log(torch.tensor(init_scale)))\n",
    "        self.log_noise = torch.nn.Parameter(torch.log(torch.tensor(init_noise)))\n",
    "\n",
    "    def construct(self):\n",
    "        self.var = torch.exp(self.log_var)\n",
    "        self.scale = torch.exp(self.log_scale)\n",
    "        self.noise = torch.exp(self.log_noise)\n",
    "        kernel = self.var * EQ().stretch(self.scale)\n",
    "        return GP(kernel), self.noise\n",
    "\n",
    "\n",
    "model = Model()\n",
    "f, noise = model.construct()\n",
    "\n",
    "# Condition on observations and make predictions before optimisation.\n",
    "f_post = f | (f(x_obs, noise), y_obs)\n",
    "prior_before = f, noise\n",
    "pred_before = f_post(x, noise).marginal_credible_bounds()\n",
    "\n",
    "# Perform optimisation.\n",
    "opt = torch.optim.Adam(model.parameters(), lr=5e-2)\n",
    "for _ in range(1000):\n",
    "    opt.zero_grad()\n",
    "    f, noise = model.construct()\n",
    "    loss = -f(x_obs, noise).logpdf(y_obs)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "\n",
    "f, noise = model.construct()\n",
    "\n",
    "# Condition on observations and make predictions after optimisation.\n",
    "f_post = f | (f(x_obs, noise), y_obs)\n",
    "prior_after = f, noise\n",
    "pred_after = f_post(x, noise).marginal_credible_bounds()\n",
    "\n",
    "\n",
    "def plot_prediction(prior, pred):\n",
    "    f, noise = prior\n",
    "    mean, lower, upper = pred\n",
    "    plt.scatter(x_obs, y_obs, label=\"Observations\", style=\"train\", s=20)\n",
    "    plt.plot(x, f_true, label=\"True\", style=\"test\")\n",
    "    plt.plot(x, mean, label=\"Prediction\", style=\"pred\")\n",
    "    plt.fill_between(x, lower, upper, style=\"pred\")\n",
    "    plt.ylim(-2, 2)\n",
    "    plt.text(\n",
    "        0.02,\n",
    "        0.02,\n",
    "        f\"var = {f.kernel.factor(0):.2f}, \"\n",
    "        f\"scale = {f.kernel.factor(1).stretches[0]:.2f}, \"\n",
    "        f\"noise = {noise:.2f}\",\n",
    "        transform=plt.gca().transAxes,\n",
    "    )\n",
    "    tweak()\n",
    "\n",
    "\n",
    "# Plot result.\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Before optimisation\")\n",
    "plot_prediction(prior_before, pred_before)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"After optimisation\")\n",
    "plot_prediction(prior_after, pred_after)\n",
    "plt.savefig(\"readme_example13_optimisation_torch.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decomposition of Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from wbml.plot import tweak\n",
    "\n",
    "from stheno import Measure, GP, EQ, RQ, Linear, Delta, Exp, B\n",
    "\n",
    "B.epsilon = 1e-10\n",
    "\n",
    "# Define points to predict at.\n",
    "x = B.linspace(0, 10, 200)\n",
    "x_obs = B.linspace(0, 7, 50)\n",
    "\n",
    "\n",
    "with Measure() as prior:\n",
    "    # Construct a latent function consisting of four different components.\n",
    "    f_smooth = GP(EQ())\n",
    "    f_wiggly = GP(RQ(1e-1).stretch(0.5))\n",
    "    f_periodic = GP(EQ().periodic(1.0))\n",
    "    f_linear = GP(Linear())\n",
    "    f = f_smooth + f_wiggly + f_periodic + 0.2 * f_linear\n",
    "\n",
    "    # Let the observation noise consist of a bit of exponential noise.\n",
    "    e_indep = GP(Delta())\n",
    "    e_exp = GP(Exp())\n",
    "    e = e_indep + 0.3 * e_exp\n",
    "\n",
    "    # Sum the latent function and observation noise to get a model for the observations.\n",
    "    y = f + 0.5 * e\n",
    "\n",
    "# Sample a true, underlying function and observations.\n",
    "(\n",
    "    f_true_smooth,\n",
    "    f_true_wiggly,\n",
    "    f_true_periodic,\n",
    "    f_true_linear,\n",
    "    f_true,\n",
    "    y_obs,\n",
    ") = prior.sample(f_smooth(x), f_wiggly(x), f_periodic(x), f_linear(x), f(x), y(x_obs))\n",
    "\n",
    "# Now condition on the observations and make predictions for the latent function and\n",
    "# its various components.\n",
    "post = prior | (y(x_obs), y_obs)\n",
    "\n",
    "pred_smooth = post(f_smooth(x))\n",
    "pred_wiggly = post(f_wiggly(x))\n",
    "pred_periodic = post(f_periodic(x))\n",
    "pred_linear = post(f_linear(x))\n",
    "pred_f = post(f(x))\n",
    "\n",
    "\n",
    "# Plot results.\n",
    "def plot_prediction(x, f, pred, x_obs=None, y_obs=None):\n",
    "    plt.plot(x, f, label=\"True\", style=\"test\")\n",
    "    if x_obs is not None:\n",
    "        plt.scatter(x_obs, y_obs, label=\"Observations\", style=\"train\", s=20)\n",
    "    mean, lower, upper = pred.marginal_credible_bounds()\n",
    "    plt.plot(x, mean, label=\"Prediction\", style=\"pred\")\n",
    "    plt.fill_between(x, lower, upper, style=\"pred\")\n",
    "    tweak()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.title(\"Prediction\")\n",
    "plot_prediction(x, f_true, pred_f, x_obs, y_obs)\n",
    "\n",
    "plt.subplot(3, 2, 3)\n",
    "plt.title(\"Smooth Component\")\n",
    "plot_prediction(x, f_true_smooth, pred_smooth)\n",
    "\n",
    "plt.subplot(3, 2, 4)\n",
    "plt.title(\"Wiggly Component\")\n",
    "plot_prediction(x, f_true_wiggly, pred_wiggly)\n",
    "\n",
    "plt.subplot(3, 2, 5)\n",
    "plt.title(\"Periodic Component\")\n",
    "plot_prediction(x, f_true_periodic, pred_periodic)\n",
    "\n",
    "plt.subplot(3, 2, 6)\n",
    "plt.title(\"Linear Component\")\n",
    "plot_prediction(x, f_true_linear, pred_linear)\n",
    "\n",
    "plt.savefig(\"readme_example2_decomposition.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn a Function, Incorporating Prior Knowledge About Its Form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import wbml.out as out\n",
    "from varz.spec import parametrised, Positive\n",
    "from varz.torch import Vars, minimise_l_bfgs_b\n",
    "from wbml.plot import tweak\n",
    "\n",
    "from stheno.torch import B, Measure, GP, EQ, Delta\n",
    "\n",
    "# Define points to predict at.\n",
    "x = B.linspace(torch.double, 0, 5, 100)\n",
    "x_obs = B.linspace(torch.double, 0, 3, 20)\n",
    "\n",
    "\n",
    "@parametrised   # To indicate that an argument of the function is a variable\n",
    "def model(\n",
    "    vs,\n",
    "    u_var: Positive = 0.5,\n",
    "    u_scale: Positive = 0.5,\n",
    "    noise: Positive = 0.5,\n",
    "    alpha: Positive = 1.2,\n",
    "):\n",
    "    with Measure():\n",
    "        # Random fluctuation:\n",
    "        u = GP(u_var * EQ().stretch(u_scale))\n",
    "        # Construct model.\n",
    "        f = u + (lambda x: x**alpha)\n",
    "    return f, noise\n",
    "\n",
    "\n",
    "# Sample a true, underlying function and observations.\n",
    "vs = Vars(torch.double)\n",
    "f_true = x**1.8 + B.sin(2 * B.pi * x)\n",
    "f, y = model(vs)\n",
    "post = f.measure | (f(x), f_true)\n",
    "y_obs = post(f(x_obs)).sample()\n",
    "\n",
    "\n",
    "def objective(vs):\n",
    "    f, noise = model(vs)\n",
    "    evidence = f(x_obs, noise).logpdf(y_obs)\n",
    "    return -evidence\n",
    "\n",
    "\n",
    "# Learn hyperparameters.\n",
    "minimise_l_bfgs_b(objective, vs, jit=True)\n",
    "f, noise = model(vs)\n",
    "\n",
    "# Print the learned parameters.\n",
    "out.kv(\"Prior\", f.display(out.format))\n",
    "vs.print()\n",
    "\n",
    "# Condition on the observations to make predictions.\n",
    "f_post = f | (f(x_obs, noise), y_obs)\n",
    "mean, lower, upper = f_post(x).marginal_credible_bounds()\n",
    "\n",
    "# Plot result.\n",
    "plt.plot(x, B.squeeze(f_true), label=\"True\", style=\"test\")\n",
    "plt.scatter(x_obs, B.squeeze(y_obs), label=\"Observations\", style=\"train\", s=20)\n",
    "plt.plot(x, mean, label=\"Prediction\", style=\"pred\")\n",
    "plt.fill_between(x, lower, upper, style=\"pred\")\n",
    "tweak()\n",
    "\n",
    "plt.savefig(\"readme_example3_parametric.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
